{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2 \n",
    "import numpy as np \n",
    "import requests \n",
    "import torch \n",
    "import torch.onnx \n",
    "from torch import nn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.asinh is already binded with onnx op asinh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.asinh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%onnx::Asinh_0 : Float(1, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu)):\n",
      "  %1 : Float(1, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Asinh[onnx_name=\"/Asinh\"](%onnx::Asinh_0), scope: __main__.MyModel:: # /tmp/ipykernel_1991/203262611.py:6:0\n",
      "  return (%1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MyModel()\n",
    "input1 = torch.randn(1, 1, 3, 3)\n",
    "torch.onnx.export(model, input1, \"asinh.onnx\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义ONNX算子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision.ops.DeformConv2d\n",
    "\n",
    "```py\n",
    "torch.ops.torchvision.deform_conv2d(\n",
    "        input,\n",
    "        weight,\n",
    "        offset,\n",
    "        mask,\n",
    "        bias,\n",
    "        stride_h,\n",
    "        stride_w,\n",
    "        pad_h,\n",
    "        pad_w,\n",
    "        dil_h,\n",
    "        dil_w,\n",
    "        n_weight_grps,\n",
    "        n_offset_grps,\n",
    "        use_mask,\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "\n",
    "class DefConv2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 18, 3)\n",
    "        self.conv2 = tv.ops.DeformConv2d(3, 3, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv2(x, self.conv1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.onnx.symbolic_helper import parse_args\n",
    "\n",
    "@parse_args('v', 'v', 'v', 'v', 'v', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'none')\n",
    "def symbolic(g,\n",
    "             input, weight, offset, mask, bias,\n",
    "             stride_h, stride_w,\n",
    "             pad_h, pad_w,\n",
    "             dil_h, dil_w,\n",
    "             n_weight_grps, n_offset_grps,\n",
    "             use_mask):\n",
    "    return g.op(\"custom::deform_conv2d\", input, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.onnx import register_custom_op_symbolic\n",
    "\n",
    "register_custom_op_symbolic(\"torchvision::deform_conv2d\", symbolic, 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(1, 3, 10, 10, strides=[300, 100, 10, 1], requires_grad=0, device=cpu),\n",
      "      %conv1.weight : Float(18, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %conv1.bias : Float(18, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %/conv1/Conv_output_0 : Float(1, 18, 8, 8, strides=[1152, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/conv1/Conv\"](%input, %conv1.weight, %conv1.bias), scope: __main__.DefConv2d::/torch.nn.modules.conv.Conv2d::conv1 # /root/projects/modelDep/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %6 : Float(*, *, *, *, strides=[192, 64, 8, 1], requires_grad=1, device=cpu) = custom::deform_conv2d[onnx_name=\"/conv2/deform_conv2d\"](%input, %/conv1/Conv_output_0), scope: __main__.DefConv2d::/torchvision.ops.deform_conv.DeformConv2d::conv2 # /root/projects/modelDep/venv/lib/python3.10/site-packages/torch/_ops.py:854:0\n",
      "  return (%6)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W shape_type_inference.cpp:1968] Warning: The shape inference of custom::deform_conv2d type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n"
     ]
    }
   ],
   "source": [
    "model = DefConv2d()\n",
    "input = torch.randn(1, 3, 10, 10)\n",
    "torch.onnx.export(model, input, \"deform.onnx\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用`torch.autograd.Function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import my_lib\n",
    "\n",
    "class MyAdd(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, a, b):\n",
    "        return my_lib.my_add(a, b)\n",
    "    \n",
    "    @staticmethod\n",
    "    def symbolic(g, a, b):\n",
    "        two = g.op(\"Constant\", value_t=torch.tensor(2))\n",
    "        a = g.op(\"Mul\", a, two)\n",
    "        return g.op(\"Add\", a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_add = MyAdd.apply\n",
    "\n",
    "class MyAddModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, a, b):\n",
    "        return my_add(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%a : Float(1, 3, 10, 10, strides=[300, 100, 10, 1], requires_grad=0, device=cpu),\n",
      "      %b : Float(1, 3, 10, 10, strides=[300, 100, 10, 1], requires_grad=0, device=cpu)):\n",
      "  %/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant\"](), scope: __main__.MyAddModule::\n",
      "  %/Mul_output_0 : Float(1, 3, 10, 10, strides=[300, 100, 10, 1], device=cpu) = onnx::Mul[onnx_name=\"/Mul\"](%a, %/Constant_output_0), scope: __main__.MyAddModule::\n",
      "  %output : Float(1, 3, 10, 10, strides=[300, 100, 10, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add\"](%/Mul_output_0, %b), scope: __main__.MyAddModule:: # /root/projects/modelDep/venv/lib/python3.10/site-packages/torch/autograd/function.py:598:0\n",
      "  return (%output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MyAddModule()\n",
    "input = torch.randn(1, 3, 10, 10)\n",
    "torch.onnx.export(model, (input, input), \"my_add.onnx\", verbose=True,\n",
    "                  input_names=[\"a\", \"b\"], output_names=[\"output\"])\n",
    "torch_output = model(input, input).detach().numpy()\n",
    "\n",
    "import onnxruntime\n",
    "sess = onnxruntime.InferenceSession(\"my_add.onnx\")\n",
    "ort_output = sess.run(None, {\"a\": input.numpy(), \"b\": input.numpy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 3, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(ort_output).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
