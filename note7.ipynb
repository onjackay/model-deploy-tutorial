{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()        \n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as Data\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train=True,                                     \n",
    "    transform=transforms.ToTensor(),                \n",
    "    download=True,                                  \n",
    ")\n",
    "test_data = datasets.MNIST(root='./mnist', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/projects/modelDep/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/root/projects/modelDep/venv/lib/python3.10/site-packages/torchvision/datasets/mnist.py:81: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/root/projects/modelDep/venv/lib/python3.10/site-packages/torchvision/datasets/mnist.py:71: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 2.3012 | test accuracy: 0.10\n",
      "Epoch:  0 | train loss: 0.1905 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.2159 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.1983 | test accuracy: 0.96\n",
      "Epoch:  0 | train loss: 0.1715 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.1688 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.2440 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.0654 | test accuracy: 0.98\n",
      "Epoch:  0 | train loss: 0.1117 | test accuracy: 0.98\n",
      "Epoch:  0 | train loss: 0.0451 | test accuracy: 0.98\n",
      "Epoch:  1 | train loss: 0.0539 | test accuracy: 0.98\n",
      "Epoch:  1 | train loss: 0.0157 | test accuracy: 0.98\n",
      "Epoch:  1 | train loss: 0.0749 | test accuracy: 0.98\n",
      "Epoch:  1 | train loss: 0.0195 | test accuracy: 0.98\n",
      "Epoch:  1 | train loss: 0.0408 | test accuracy: 0.98\n",
      "Epoch:  1 | train loss: 0.0159 | test accuracy: 0.98\n",
      "Epoch:  1 | train loss: 0.1830 | test accuracy: 0.98\n",
      "Epoch:  1 | train loss: 0.1128 | test accuracy: 0.98\n",
      "Epoch:  1 | train loss: 0.0917 | test accuracy: 0.98\n",
      "Epoch:  1 | train loss: 0.0319 | test accuracy: 0.98\n",
      "Epoch:  2 | train loss: 0.1231 | test accuracy: 0.98\n",
      "Epoch:  2 | train loss: 0.0620 | test accuracy: 0.98\n",
      "Epoch:  2 | train loss: 0.0197 | test accuracy: 0.99\n",
      "Epoch:  2 | train loss: 0.0098 | test accuracy: 0.98\n",
      "Epoch:  2 | train loss: 0.1319 | test accuracy: 0.99\n",
      "Epoch:  2 | train loss: 0.0121 | test accuracy: 0.99\n",
      "Epoch:  2 | train loss: 0.0315 | test accuracy: 0.99\n",
      "Epoch:  2 | train loss: 0.0059 | test accuracy: 0.99\n",
      "Epoch:  2 | train loss: 0.0196 | test accuracy: 0.98\n",
      "Epoch:  2 | train loss: 0.0038 | test accuracy: 0.99\n",
      "Epoch:  3 | train loss: 0.0849 | test accuracy: 0.99\n",
      "Epoch:  3 | train loss: 0.0359 | test accuracy: 0.99\n",
      "Epoch:  3 | train loss: 0.0059 | test accuracy: 0.99\n",
      "Epoch:  3 | train loss: 0.0333 | test accuracy: 0.98\n",
      "Epoch:  3 | train loss: 0.0159 | test accuracy: 0.99\n",
      "Epoch:  3 | train loss: 0.0488 | test accuracy: 0.99\n",
      "Epoch:  3 | train loss: 0.0808 | test accuracy: 0.99\n",
      "Epoch:  3 | train loss: 0.0264 | test accuracy: 0.99\n",
      "Epoch:  3 | train loss: 0.1361 | test accuracy: 0.99\n",
      "Epoch:  3 | train loss: 0.0028 | test accuracy: 0.99\n",
      "Epoch:  4 | train loss: 0.0286 | test accuracy: 0.99\n",
      "Epoch:  4 | train loss: 0.0036 | test accuracy: 0.99\n",
      "Epoch:  4 | train loss: 0.0475 | test accuracy: 0.99\n",
      "Epoch:  4 | train loss: 0.0029 | test accuracy: 0.99\n",
      "Epoch:  4 | train loss: 0.0218 | test accuracy: 0.99\n",
      "Epoch:  4 | train loss: 0.0087 | test accuracy: 0.99\n",
      "Epoch:  4 | train loss: 0.0157 | test accuracy: 0.99\n",
      "Epoch:  4 | train loss: 0.0443 | test accuracy: 0.99\n",
      "Epoch:  4 | train loss: 0.0037 | test accuracy: 0.99\n",
      "Epoch:  4 | train loss: 0.0201 | test accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# train model\n",
    "model = CNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "for epoch in range(5):\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):\n",
    "        b_x, b_y = b_x.to(device), b_y.to(device)\n",
    "        output = model(b_x)[0]               \n",
    "        loss = loss_func(output, b_y)        \n",
    "        optimizer.zero_grad()               \n",
    "        loss.backward()                     \n",
    "        optimizer.step()                    \n",
    "\n",
    "        if step % 100 == 0:\n",
    "            test_output, last_layer = model(test_data.test_data.to(device).view(-1, 1, 28, 28).float())\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = (pred_y == test_data.test_labels.to(device)).sum().item() / float(test_data.test_labels.size(0))\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.cpu().numpy(), '| test accuracy: %.2f' % accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converse to tensorrt via onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(1, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cuda:0),\n",
      "      %conv1.0.weight : Float(16, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=1, device=cuda:0),\n",
      "      %conv1.0.bias : Float(16, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %conv2.0.weight : Float(32, 16, 5, 5, strides=[400, 25, 5, 1], requires_grad=1, device=cuda:0),\n",
      "      %conv2.0.bias : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %out.weight : Float(10, 1568, strides=[1568, 1], requires_grad=1, device=cuda:0),\n",
      "      %out.bias : Float(10, strides=[1], requires_grad=1, device=cuda:0)):\n",
      "  %/conv1/conv1.0/Conv_output_0 : Float(1, 16, 28, 28, strides=[12544, 784, 28, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/conv1/conv1.0/Conv\"](%input, %conv1.0.weight, %conv1.0.bias), scope: __main__.CNN::/torch.nn.modules.container.Sequential::conv1/torch.nn.modules.conv.Conv2d::conv1.0 # /root/projects/modelDep/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/conv1/conv1.1/Relu_output_0 : Float(1, 16, 28, 28, strides=[12544, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"/conv1/conv1.1/Relu\"](%/conv1/conv1.0/Conv_output_0), scope: __main__.CNN::/torch.nn.modules.container.Sequential::conv1/torch.nn.modules.activation.ReLU::conv1.1 # /root/projects/modelDep/venv/lib/python3.10/site-packages/torch/nn/functional.py:1500:0\n",
      "  %/conv1/conv1.2/MaxPool_output_0 : Float(1, 16, 14, 14, strides=[3136, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::MaxPool[ceil_mode=0, dilations=[1, 1], kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/conv1/conv1.2/MaxPool\"](%/conv1/conv1.1/Relu_output_0), scope: __main__.CNN::/torch.nn.modules.container.Sequential::conv1/torch.nn.modules.pooling.MaxPool2d::conv1.2 # /root/projects/modelDep/venv/lib/python3.10/site-packages/torch/nn/functional.py:796:0\n",
      "  %/conv2/conv2.0/Conv_output_0 : Float(1, 32, 14, 14, strides=[6272, 196, 14, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/conv2/conv2.0/Conv\"](%/conv1/conv1.2/MaxPool_output_0, %conv2.0.weight, %conv2.0.bias), scope: __main__.CNN::/torch.nn.modules.container.Sequential::conv2/torch.nn.modules.conv.Conv2d::conv2.0 # /root/projects/modelDep/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/conv2/conv2.1/Relu_output_0 : Float(1, 32, 14, 14, strides=[6272, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"/conv2/conv2.1/Relu\"](%/conv2/conv2.0/Conv_output_0), scope: __main__.CNN::/torch.nn.modules.container.Sequential::conv2/torch.nn.modules.activation.ReLU::conv2.1 # /root/projects/modelDep/venv/lib/python3.10/site-packages/torch/nn/functional.py:1500:0\n",
      "  %/conv2/conv2.2/MaxPool_output_0 : Float(1, 32, 7, 7, strides=[1568, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::MaxPool[ceil_mode=0, dilations=[1, 1], kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/conv2/conv2.2/MaxPool\"](%/conv2/conv2.1/Relu_output_0), scope: __main__.CNN::/torch.nn.modules.container.Sequential::conv2/torch.nn.modules.pooling.MaxPool2d::conv2.2 # /root/projects/modelDep/venv/lib/python3.10/site-packages/torch/nn/functional.py:796:0\n",
      "  %/Constant_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1 [ CPULongType{2} ], onnx_name=\"/Constant\"](), scope: __main__.CNN:: # /tmp/ipykernel_23373/4055600164.py:28:0\n",
      "  %hidden : Float(1, 1568, strides=[1568, 1], requires_grad=1, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name=\"/Reshape\"](%/conv2/conv2.2/MaxPool_output_0, %/Constant_output_0), scope: __main__.CNN:: # /tmp/ipykernel_23373/4055600164.py:28:0\n",
      "  %output : Float(1, 10, strides=[10, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/out/Gemm\"](%hidden, %out.weight, %out.bias), scope: __main__.CNN::/torch.nn.modules.linear.Linear::out # /root/projects/modelDep/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:116:0\n",
      "  return (%output, %hidden)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# generate ONNX model\n",
    "torch.onnx.export(model, torch.randn(1, 1, 28, 28).to(device), \"mnist.onnx\", \n",
    "                  verbose=True, input_names=['input'], output_names=['output', 'hidden'])\n",
    "onnx_model = onnx.load(\"mnist.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The build phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/25/2024-11:22:31] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "# create builder and network\n",
    "logger = trt.Logger(trt.Logger.WARNING)\n",
    "builder = trt.Builder(logger)\n",
    "EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "network = builder.create_network(EXPLICIT_BATCH)\n",
    "\n",
    "# parse onnx\n",
    "parser = trt.OnnxParser(network, logger)\n",
    "success = parser.parse_from_file(\"mnist.onnx\")\n",
    "\n",
    "config = builder.create_builder_config()\n",
    "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 20)\n",
    "profile = builder.create_optimization_profile()\n",
    "profile.set_shape(\"input\", (1, 1, 28, 28), (1, 1, 28, 28), (1, 1, 28, 28))\n",
    "\n",
    "# create engine\n",
    "engine = builder.build_serialized_network(network, config)\n",
    "\n",
    "with open(\"mnist.engine\", \"wb\") as f:\n",
    "    f.write(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deserialize a plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = trt.Runtime(logger)\n",
    "engine = runtime.deserialize_cuda_engine(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/25/2024-11:39:54] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n",
      "[05/25/2024-11:39:55] [TRT] [E] 1: [executionContext.cpp::executeInternal::1011] Error Code 1: Cuda Runtime (an illegal memory access was encountered)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "# populate input buffer\n",
    "input_shape = (1, 1, 28, 28)\n",
    "input_data = torch.randn(input_shape).to(device)\n",
    "context.set_tensor_address(\"input\", input_data.data_ptr())\n",
    "\n",
    "# populate output buffer\n",
    "output_shape = (1, 10)\n",
    "output_data = torch.zeros(output_shape).to(device)\n",
    "context.set_tensor_address(\"output\", output_data.data_ptr())\n",
    "\n",
    "# get pointer to CUDA stream\n",
    "stream = torch.cuda.current_stream().cuda_stream\n",
    "\n",
    "# start inference\n",
    "context.execute_v2(\n",
    "    bindings=[input_data.data_ptr(), output_data.data_ptr()],\n",
    "    # stream_handle=stream\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
